{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhhbQwGnss8ISqyhXXHJ3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyake/Open-AI-LLM-Langchain-Projects/blob/main/RAG_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dAUfpxDranWl"
      },
      "outputs": [],
      "source": [
        "corpus_of_documents = [\n",
        "    \"Take a stroll along the beach and feel the sand between your toes.\",\n",
        "    \"Explore a nearby forest and marvel at the towering trees.\",\n",
        "    \"Join a photography club and capture the beauty of the world.\",\n",
        "    \"Volunteer at a local charity and make a positive difference.\",\n",
        "    \"Attend a cooking class and learn to create delicious dishes.\",\n",
        "    \"Visit an art gallery and immerse yourself in creativity.\",\n",
        "    \"Go on a road trip and discover hidden gems along the way.\",\n",
        "    \"Take a dance lesson and let music guide your movements.\",\n",
        "    \"Host a game night with friends and enjoy friendly competition.\",\n",
        "    \"Attend a meditation retreat and find inner peace.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"India is a country for indians and for everyone\"\n",
        "from collections import Counter\n",
        "import math\n",
        "user_query=\"I am an indian and i live in india\""
      ],
      "metadata": {
        "id": "bFEAjvKjv1lg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_tokens=user_query.lower().split(\" \")\n",
        "query_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v-RydHev1gV",
        "outputId": "17c5dd22-2eb8-4059-ea30-a135d77b34d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'an', 'indian', 'and', 'i', 'live', 'in', 'india']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_tokens=document.lower().split(\" \")"
      ],
      "metadata": {
        "id": "DwIoCogFx5gK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "query_counter=Counter(query_tokens)"
      ],
      "metadata": {
        "id": "15vQM-tzyD6E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_counter=Counter(document_tokens)"
      ],
      "metadata": {
        "id": "3p4yCNDhyKqS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed=[]\n",
        "for token in query_counter.keys():\n",
        "  embed.append(query_counter[token])"
      ],
      "metadata": {
        "id": "fyhwp2fwyT2k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e5EuMAbD60S",
        "outputId": "1f80768c-bebf-4e2e-de0a-1828feb2be9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed2=[]\n",
        "for token in document_counter.keys():\n",
        "  embed2.append(document_counter[token])"
      ],
      "metadata": {
        "id": "kgm_eVRsD7VX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#similarity score between user_query and this document\n",
        "for tokens in query_counter.keys() & document_counter.keys():\n",
        "  print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j1kVNTYGjsZ",
        "outputId": "f2f845f5-9993-4d96-b21a-6b2817d1f6c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india\n",
            "and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query2=\"i am an indian and i live in india and i love indian food\"\n",
        "document2=\"India is a country for indians and for everyone and for those who loves indian food\"\n",
        "document2_token=document2.lower().split(\" \")\n",
        "user_query_2_token=user_query2.lower().split(\" \")"
      ],
      "metadata": {
        "id": "kH5u1O2RH81z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "query_counter2=Counter(user_query_2_token)\n",
        "document2_counter2=Counter(document2_token)"
      ],
      "metadata": {
        "id": "dt96QhoNIQCp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_counter_3=Counter(document2)"
      ],
      "metadata": {
        "id": "LTpvJeQeIb4h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_counter2.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym5-_84RIgT7",
        "outputId": "d898a84b-4426-4e5f-f73e-7a14a6924cbc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([3, 1, 1, 2, 2, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document2_counter2.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDKWjKjYJ5QX",
        "outputId": "13fe6ec6-51f9-4fc4-e5a3-3390a61df087"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similarity score between user_query and this document\n",
        "mylist=[]\n",
        "for tokens in query_counter2.keys() & document2_counter2.keys():\n",
        "  mylist.append(query_counter2[tokens]*document2_counter2[tokens])"
      ],
      "metadata": {
        "id": "WBX_mZO-IhBj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mylist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8oBvLdNJEiz",
        "outputId": "1db3e99a-47b7-44dc-e028-05e9b1e16c4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 4, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product=sum(mylist)\n",
        "query_magnitude=math.sqrt(sum(query_counter2[token]**2 for token in query_counter2))\n",
        "document_magnitude=math.sqrt(sum(document2_counter2[token]**2 for token in document2_counter2))"
      ],
      "metadata": {
        "id": "-wLoOsZ0J2uz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity=(dot_product)/(query_magnitude*document_magnitude)\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBylSUwNt39",
        "outputId": "7b53a255-54dd-4669-ac50-0ac2e86e3c83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33333333333333337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(query, document):\n",
        "  query_tokens=query.lower().split(\" \")\n",
        "  document_tokens=document.lower().split(\" \")\n",
        "\n",
        "  query_counter=Counter(query_tokens)\n",
        "  document_counter=Counter(document_tokens)\n",
        "\n",
        "  dot_product=sum(query_counter[token]* document_counter[token] for token in query_counter.keys() & document_counter.keys())\n",
        "  query_magnitude=math.sqrt(sum(query_counter[token]**2 for token in query_counter))\n",
        "  document_magnitude=math.sqrt(sum(document_counter[token]**2 for token in document_counter))\n",
        "\n",
        "  #similarity\n",
        "  similarity=dot_product/(query_magnitude*document_magnitude) if query_magnitude*document_magnitude!=0 else 0\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "Yc2rotJSOCIa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"sunny is a genai engineer he is skilled in Data Sci\"\n",
        "user_query=\" Is sunny good with cooking?\""
      ],
      "metadata": {
        "id": "hnmQRgx9Pngq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(document, user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EUf9IlQU6x",
        "outputId": "24f69131-b251-47e1-9a12-6479f632ef76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33968311024337877"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch3pTFrbmmHD",
        "outputId": "874d18e2-5166-47c8-fd87-0562ea4b14ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "OPENAI_API_KEY=userdata.get('openai')\n",
        "os.environ['OPENAI_API_KEY']=OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "DlqeyMfwQX9d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client=OpenAI()\n",
        "completion=client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\"content\":\"you are a helpful assistant\"},\n",
        "        {\"role\": \"user\",\"content\": \"Can you tell me the prime minister of india in 2024?\"}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "L8baGXPAmiDR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eBjntaomlOE",
        "outputId": "ade51308-3f4b-4e80-eb78-d2e9f540fa8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but as an AI, I cannot predict the future political situation. As of my last update, Narendra Modi was serving as the Prime Minister of India. It's best to keep up with current news and events to know who the Prime Minister will be in 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_response(query, corpus):\n",
        "  similarities=[]\n",
        "  for doc in corpus:\n",
        "    similarity=cosine_similarity(query, doc)\n",
        "    similarities.append(similarity)\n",
        "  return corpus_of_documents[similarities.index(max(similarities))]\n"
      ],
      "metadata": {
        "id": "ZlZ3d8vknU7Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query=\"how can i cook deliciously?\""
      ],
      "metadata": {
        "id": "358atsMmoiya"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_document=return_response(user_query,corpus_of_documents)"
      ],
      "metadata": {
        "id": "cDBDQyDIpLYF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input=\"how can i cook deliciously?\""
      ],
      "metadata": {
        "id": "-XiM96XVALXV"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_response=[]\n",
        "prompt=f\"\"\"\n",
        "This is the given information {relevant_document}\n",
        "The user input is : {user_input}\n",
        "Compile the information to the user based on the given information and the user input.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "S2oxHZP7pRTr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client=OpenAI()\n",
        "completion=client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\"content\":\"you are a funny bot, You answer in very short sentences.\"},\n",
        "        {\"role\": \"user\",\"content\": prompt}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "oVcOsiNqpeJI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDvnkeq1Amha",
        "outputId": "98f5f1ac-9c1b-45f4-86e8-a2bd1662ee2b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can't cook on the beach, but you can enjoy the beach.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJZLquQcFrXZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}