{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "     ---------------------------------------- 0.0/129.4 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/129.4 kB ? eta -:--:--\n",
      "     ----------------- ------------------- 61.4/129.4 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 129.4/129.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.4 MB 21.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.4/8.4 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.3/8.4 MB 44.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 44.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "   ---------------------------------------- 0.0/330.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 330.1/330.1 kB 20.0 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.6/15.8 MB 84.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 6.1/15.8 MB 78.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.1/15.8 MB 65.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.8/15.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.3/15.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 152.8/152.8 kB ? eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.5/269.5 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.2-cp39-none-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.7/269.7 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 70.4 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 163.8/163.8 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB ? eta 0:00:00\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ---------------------------------------- 0.0/170.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 170.9/170.9 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.6/61.6 kB ? eta 0:00:00\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB ? eta 0:00:00\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2024.2.0 huggingface-hub-0.20.3 idna-3.6 numpy-1.26.4 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 safetensors-0.4.2 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.37.2 urllib3-2.2.1\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.0-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.0-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl.metadata (32 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.7 kB ? eta -:--:--\n",
      "   --------------------------------------  532.5/536.7 kB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 536.7/536.7 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB ? eta 0:00:00\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 166.4/166.4 kB ? eta 0:00:00\n",
      "Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "   ---------------------------------------- 0.0/366.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 366.0/366.0 kB 23.7 MB/s eta 0:00:00\n",
      "Downloading pyarrow-15.0.0-cp39-cp39-win_amd64.whl (24.9 MB)\n",
      "   ---------------------------------------- 0.0/24.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/24.9 MB 118.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 4.6/24.9 MB 58.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 7.9/24.9 MB 62.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.8/24.9 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.5/24.9 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.4/24.9 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.7/24.9 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.9 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/24.9 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.9/24.9 MB 54.4 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.4/133.4 kB ? eta 0:00:00\n",
      "Downloading pandas-2.2.0-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 97.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.9/11.6 MB 76.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.5/11.6 MB 68.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 59.5 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.7/50.7 kB ? eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 505.5/505.5 kB ? eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 345.4/345.4 kB ? eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, attrs, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.2.0\n",
      "    Uninstalling fsspec-2024.2.0:\n",
      "      Successfully uninstalled fsspec-2024.2.0\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 datasets-2.17.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.0 pyarrow-15.0.0 pyarrow-hotfix-0.6 pytz-2024.1 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "Collecting tokenizer\n",
      "  Downloading tokenizer-3.4.3-py2.py3-none-any.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.2 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.2 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.2/42.2 kB 515.6 kB/s eta 0:00:00\n",
      "Downloading tokenizer-3.4.3-py2.py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 112.3/112.3 kB 3.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizer\n",
      "Successfully installed tokenizer-3.4.3\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from seqeval) (1.26.4)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval)\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading scipy-1.12.0-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.4 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     --------------------------------------- 60.4/60.4 kB 48.7 kB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.6 MB 13.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.3/10.6 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.9/10.6 MB 39.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.0/10.6 MB 46.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.6 MB 46.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 46.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Downloading scipy-1.12.0-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 3.0/46.2 MB 63.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 6.0/46.2 MB 63.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 8.7/46.2 MB 61.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 12.2/46.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 15.0/46.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 18.6/46.2 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 21.2/46.2 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 23.3/46.2 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 26.1/46.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 28.6/46.2 MB 54.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 30.8/46.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 33.4/46.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 36.0/46.2 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.6/46.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.8/46.2 MB 59.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.4/46.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 46.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, seqeval\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 scipy-1.12.0 seqeval-1.2.2 threadpoolctl-3.3.0\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from transformers[torch]) (4.66.2)\n",
      "Collecting torch!=1.12.0,>=1.11 (from transformers[torch])\n",
      "  Downloading torch-2.2.0-cp39-cp39-win_amd64.whl.metadata (26 kB)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Collecting sympy (from torch!=1.12.0,>=1.11->transformers[torch])\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch!=1.12.0,>=1.11->transformers[torch])\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch!=1.12.0,>=1.11->transformers[torch])\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch!=1.12.0,>=1.11->transformers[torch])\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch!=1.12.0,>=1.11->transformers[torch])\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "   ---------------------------------------- 0.0/280.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 280.0/280.0 kB 16.9 MB/s eta 0:00:00\n",
      "Downloading torch-2.2.0-cp39-cp39-win_amd64.whl (198.5 MB)\n",
      "   ---------------------------------------- 0.0/198.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/198.5 MB 16.6 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 2.0/198.5 MB 21.2 MB/s eta 0:00:10\n",
      "    --------------------------------------- 3.7/198.5 MB 26.1 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 6.2/198.5 MB 30.3 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 7.8/198.5 MB 33.0 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 10.0/198.5 MB 33.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 12.4/198.5 MB 43.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 14.8/198.5 MB 50.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 17.0/198.5 MB 46.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 19.3/198.5 MB 54.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 22.4/198.5 MB 50.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 25.2/198.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 27.6/198.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 30.7/198.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 33.9/198.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 36.2/198.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 39.6/198.5 MB 65.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 42.9/198.5 MB 65.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 45.8/198.5 MB 72.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 49.3/198.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 52.5/198.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 56.1/198.5 MB 81.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 59.4/198.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 63.0/198.5 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 66.3/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 69.4/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 72.8/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 76.2/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 79.3/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 82.8/198.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 85.9/198.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 88.8/198.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 92.1/198.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 95.4/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 98.6/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 101.8/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 105.4/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 108.6/198.5 MB 73.1 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 111.7/198.5 MB 73.1 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 114.7/198.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 118.3/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 121.4/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 124.7/198.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 127.8/198.5 MB 65.2 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 131.0/198.5 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 134.3/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 137.4/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 140.3/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 143.6/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 147.1/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 150.1/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 153.4/198.5 MB 65.2 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 155.8/198.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 158.8/198.5 MB 59.8 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 162.9/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 164.6/198.5 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 166.2/198.5 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 170.0/198.5 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 173.7/198.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 177.3/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 181.4/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.2/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 189.1/198.5 MB 93.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.0/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  196.7/198.5 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.5/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.5/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.5/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.5/198.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 198.5/198.5 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.2/133.2 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 102.3 MB/s eta 0:00:00\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 3.7/5.7 MB 77.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 73.5 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch, accelerate\n",
      "Successfully installed MarkupSafe-2.1.5 accelerate-0.27.2 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.2.0\n",
      "Requirement already satisfied: seqeval in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from seqeval) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install tokenizer\n",
    "!pip install seqeval\n",
    "!pip install transformers[torch]\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml-core\n",
    "!pip install --upgrade azureml-core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np \n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll2003=datasets.load_dataset('conll2003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003['train'].features['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003['train'].features['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text=conll2003['train'][0]\n",
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input=tokenizer(example_text['tokens'], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenz=tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'eu',\n",
       " 'rejects',\n",
       " 'german',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'british',\n",
       " 'lamb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 0\n",
      "2 7\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 7\n",
      "7 0\n",
      "8 0\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(example_text['ner_tags']):\n",
    "    print(i,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs=tokenizer(examples['tokens'],truncation=False, is_split_into_words=True)\n",
    "    labels=[]\n",
    "    for i , label in enumerate(examples['ner_tags']):\n",
    "        word_ids=tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx=None\n",
    "        label_ids=[]\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx!=previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx=word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs['labels']=labels \n",
    "    return tokenized_inputs   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=tokenize_and_align_labels(conll2003['train'][4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________ -100\n",
      "germany_________________________________ 5\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "representative__________________________ 0\n",
      "to______________________________________ 0\n",
      "the_____________________________________ 0\n",
      "european________________________________ 3\n",
      "union___________________________________ 4\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "veterinary______________________________ 0\n",
      "committee_______________________________ 0\n",
      "werner__________________________________ 1\n",
      "z_______________________________________ 2\n",
      "##wing__________________________________ 2\n",
      "##mann__________________________________ 2\n",
      "said____________________________________ 0\n",
      "on______________________________________ 0\n",
      "wednesday_______________________________ 0\n",
      "consumers_______________________________ 0\n",
      "should__________________________________ 0\n",
      "buy_____________________________________ 0\n",
      "sheep___________________________________ 0\n",
      "##me____________________________________ 0\n",
      "##at____________________________________ 0\n",
      "from____________________________________ 0\n",
      "countries_______________________________ 0\n",
      "other___________________________________ 0\n",
      "than____________________________________ 0\n",
      "britain_________________________________ 5\n",
      "until___________________________________ 0\n",
      "the_____________________________________ 0\n",
      "scientific______________________________ 0\n",
      "advice__________________________________ 0\n",
      "was_____________________________________ 0\n",
      "clearer_________________________________ 0\n",
      "._______________________________________ 0\n",
      "[SEP]___________________________________ -100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(q['input_ids'][0]),q['labels'][0]):\n",
    "    print(f\"{token:_<40} {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets=conll2003.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 440M/440M [00:06<00:00, 71.8MB/s] \n",
      "c:\\Users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\satya\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForTokenClassification.from_pretrained('bert-base-uncased', num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_44500\\1565578648.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric=datasets.load_metric('seqeval')\n",
      "c:\\Users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages\\datasets\\load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 6.33kB [00:00, ?B/s]                       \n"
     ]
    }
   ],
   "source": [
    "metric=datasets.load_metric('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=conll2003['train'][0]\n",
    "label_list=conll2003['train'].features['ner_tags'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    pred_logits, labels=eval_preds\n",
    "    pred_logits=np.argmax(pred_logits, axis=2)\n",
    "    predictions=[\n",
    "        [label_list[eval_preds] for (eval_preds,l) in zip(prediction, label) if l!=-100 ]\n",
    "        for prediction, label in zip(pred_logits, labels)\n",
    "    ]\n",
    "\n",
    "    true_labels=[\n",
    "\n",
    "        [label_list[l] for (eval_preds, l) in zip(predictions, label) if l!=-100]\n",
    "        for prediction, label in zip(pred_logits,labels)\n",
    "    ]\n",
    "\n",
    "    results=metric.compute(predictions=predictions, references=true_labels)\n",
    "    return {\n",
    "        \"Precision\": results['overall_precision'],\n",
    "        \"Recall\": results['overall_recall'],\n",
    "        \"F1\": results['overall_accuracy']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=TrainingArguments(\n",
    "    \"test-ner\",evaluation_strategy='epoch',\n",
    "    learning_rate=0.0005,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "trainer=Trainer(\n",
    "    model, \n",
    "    args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 500/878 [18:20<14:08,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3774, 'learning_rate': 0.00021526195899772212, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [31:37<00:00,  1.91s/it]\n",
      "100%|██████████| 878/878 [33:31<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14566431939601898, 'eval_Precision': 0.8255584756898817, 'eval_Recall': 0.8433829287392326, 'eval_F1': 0.9620474367324893, 'eval_runtime': 113.4954, 'eval_samples_per_second': 28.636, 'eval_steps_per_second': 1.797, 'epoch': 1.0}\n",
      "{'train_runtime': 2011.2851, 'train_samples_per_second': 6.981, 'train_steps_per_second': 0.437, 'train_loss': 0.300856414308309, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=878, training_loss=0.300856414308309, metrics={'train_runtime': 2011.2851, 'train_samples_per_second': 6.981, 'train_steps_per_second': 0.437, 'train_loss': 0.300856414308309, 'epoch': 1.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('NER_transformer_fine_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NER1_tokenizer\\\\tokenizer_config.json',\n",
       " 'NER1_tokenizer\\\\special_tokens_map.json',\n",
       " 'NER1_tokenizer\\\\vocab.txt',\n",
       " 'NER1_tokenizer\\\\added_tokens.json',\n",
       " 'NER1_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('NER1_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label={\n",
    "    str(i): label for i, label in enumerate(label_list)\n",
    "}\n",
    "\n",
    "label2id={\n",
    "    label: str(i) for i, label in enumerate(label_list)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'B-PER',\n",
       " '2': 'I-PER',\n",
       " '3': 'B-ORG',\n",
       " '4': 'I-ORG',\n",
       " '5': 'B-LOC',\n",
       " '6': 'I-LOC',\n",
       " '7': 'B-MISC',\n",
       " '8': 'I-MISC'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config=json.load(open('C:/Users/satya/Desktop/NER_transformer_fine_tuned/config.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['label2id']=label2id\n",
    "config['id2label']=id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(config,open('C:/Users/satya/Desktop/NER_transformer_fine_tuned/config.json',\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_name_or_path': 'bert-base-uncased',\n",
       " 'architectures': ['BertForTokenClassification'],\n",
       " 'attention_probs_dropout_prob': 0.1,\n",
       " 'classifier_dropout': None,\n",
       " 'gradient_checkpointing': False,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'id2label': {'0': 'O',\n",
       "  '1': 'B-PER',\n",
       "  '2': 'I-PER',\n",
       "  '3': 'B-ORG',\n",
       "  '4': 'I-ORG',\n",
       "  '5': 'B-LOC',\n",
       "  '6': 'I-LOC',\n",
       "  '7': 'B-MISC',\n",
       "  '8': 'I-MISC'},\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'label2id': {'O': '0',\n",
       "  'B-PER': '1',\n",
       "  'I-PER': '2',\n",
       "  'B-ORG': '3',\n",
       "  'I-ORG': '4',\n",
       "  'B-LOC': '5',\n",
       "  'I-LOC': '6',\n",
       "  'B-MISC': '7',\n",
       "  'I-MISC': '8'},\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'max_position_embeddings': 512,\n",
       " 'model_type': 'bert',\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'pad_token_id': 0,\n",
       " 'position_embedding_type': 'absolute',\n",
       " 'torch_dtype': 'float32',\n",
       " 'transformers_version': '4.37.2',\n",
       " 'type_vocab_size': 2,\n",
       " 'use_cache': True,\n",
       " 'vocab_size': 30522}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open('C:/Users/satya/Desktop/NER_transformer_fine_tuned/config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine_tuned=AutoModelForTokenClassification.from_pretrained('C:/Users/satya/Desktop/NER_transformer_fine_tuned')\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pipeline=pipeline('ner',model=model_fine_tuned, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "example='Sudhanshu kumar is the founded of Ineuron'\n",
    "example1='Modi is working in BJP'\n",
    "example1='Microsoft windows created their software by idea that came from the window of the house'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-MISC',\n",
       "  'score': 0.78552896,\n",
       "  'index': 1,\n",
       "  'word': 'microsoft',\n",
       "  'start': 0,\n",
       "  'end': 9},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.86615276,\n",
       "  'index': 2,\n",
       "  'word': 'windows',\n",
       "  'start': 10,\n",
       "  'end': 17}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_pipeline(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
