{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1G8LUEfK2D8D8DZoY7CoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyake/Open-AI-LLM-Langchain-Projects/blob/main/RAG_with_vectorDB_weaviate_in_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V3OLCPZ0J4z3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WdyWPYUNCZ8Y"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai langchain weaviate-client tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "SaIuwetYCg_K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\""
      ],
      "metadata": {
        "id": "91SjxJnSxMfK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=requests.get(url)\n",
        "with open('state_of_the_union.txt','w') as f:\n",
        "  f.write(res.text)"
      ],
      "metadata": {
        "id": "pAQBuqINxEge"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_loader=TextLoader('/content/state_of_the_union.txt')"
      ],
      "metadata": {
        "id": "97DnEy5HyK9U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=text_loader.load()"
      ],
      "metadata": {
        "id": "i2uhY0GzybqL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "EX1seHbEyhD6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter=CharacterTextSplitter(chunk_size=500, chunk_overlap=50)"
      ],
      "metadata": {
        "id": "yUWAqAg57jc0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks=splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "MYuD1sYf7nkz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[5].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgf6TIK68WiX",
        "outputId": "22baf06f-308d-43bc-c089-4902a4b1cff7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We prepared extensively and carefully. \n",
            "\n",
            "We spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \n",
            "\n",
            "I spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \n",
            "\n",
            "We countered Russiaâ€™s lies with truth.   \n",
            "\n",
            "And now that he has acted the free world is holding him accountable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from langchain.vectorstores import Weaviate\n",
        "from weaviate import Client\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "client=Client(\n",
        "    embedded_options=EmbeddedOptions()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lPrOYs68aO5",
        "outputId": "c1640518-2532-47eb-90ab-721174dc325d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedded weaviate is already listening on port 8079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "f4puqzSzIpyG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "api=userdata.get('openai')\n",
        "os.environ['OPENAI_API_KEY']=api\n",
        "vectorstore=Weaviate.from_documents(\n",
        "    client=client,\n",
        "    documents=chunks,\n",
        "    embedding=OpenAIEmbeddings()\n",
        ")"
      ],
      "metadata": {
        "id": "jwn3ETk1Doyc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "qSk0UWaDIYzH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "rcvqqmMJKTJd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"\"\"\n",
        "You are an assistant for question-answering tasks.\n",
        "Use the following prices of retrived context to answer the question.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UP6Q4mcxLDED"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "SdRAn9qzQgJf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79lbzojhQkOc",
        "outputId": "4d796412-4933-406d-e077-c8b1f5f43516"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nYou are an assistant for question-answering tasks.\\nUse the following prices of retrived context to answer the question.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n'))])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ],
      "metadata": {
        "id": "d6poTysxQqUF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5JWwYgocv5Z",
        "outputId": "8c216321-6bbc-4def-ae93-8fe567f9f8bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"\"\" why ukraine wants to join nato\"\"\"\n",
        "output_parser=StrOutputParser()"
      ],
      "metadata": {
        "id": "5yel-cVKdB8H"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain=(\n",
        "    {'context': retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | output_parser\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "QHspYlx_gaU_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU0hNA9Gg7sv",
        "outputId": "73db7a43-8f2b-4b6d-89d4-c95b81552fdc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  context: VectorStoreRetriever(tags=['Weaviate', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.weaviate.Weaviate object at 0x7bcc37a18d90>),\n",
              "  question: RunnablePassthrough()\n",
              "}\n",
              "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nYou are an assistant for question-answering tasks.\\nUse the following prices of retrived context to answer the question.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7bcc3d9d7af0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7bcc3cf3efb0>, openai_api_key='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', openai_proxy='')\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "klwD4jR1i2nw",
        "outputId": "5ca55102-cf16-4cd3-aacd-5c958a4d815b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ukraine wants to join NATO in order to secure peace and stability in Europe, especially after facing aggression from dictators like Putin. By joining NATO, Ukraine hopes to receive military, economic, and humanitarian assistance from the alliance to defend its territory and fight for freedom.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qgvZW7xlE2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}